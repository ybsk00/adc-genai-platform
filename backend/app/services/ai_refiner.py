"""
AI Refiner Service
ë¯¸ì •ì œ ë ˆì½”ë“œë¥¼ LLMìœ¼ë¡œ ë¶„ì„í•˜ì—¬ outcome_type, failure_reason ë“±ì„ ì¶”ì¶œ
"""
import asyncio
import logging
import json
from typing import Dict, Any, Optional
from datetime import datetime

from app.core.supabase import supabase
from app.core.config import settings
import google.generativeai as genai
from app.services.cost_tracker import cost_tracker
from json_repair import repair_json

logger = logging.getLogger(__name__)

class AIRefiner:
    def __init__(self):
        self.batch_size = 10  # í•œ ë²ˆì— ì²˜ë¦¬í•  ë ˆì½”ë“œ ìˆ˜
        self.processed_count = 0
        self.error_count = 0

    async def _is_system_paused(self) -> bool:
        """ì‹œìŠ¤í…œ ì¼ì‹œì •ì§€ ìƒíƒœ í™•ì¸"""
        try:
            res = supabase.table("system_config").select("value").eq("key", "AI_REFINER_STATUS").execute()
            return res.data[0]["value"] == "PAUSED" if res.data else False
        except:
            return False

    async def refine_single_record(self, record: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ë‹¨ì¼ ë ˆì½”ë“œ LLM ë¶„ì„ (Google SDK ì§ì ‘ í˜¸ì¶œ)"""
        try:
            # ë¹„ìš© í•œë„ ì²´í¬
            if await cost_tracker.is_over_limit():
                logger.warning("âš ï¸ Daily LLM cost limit reached. Skipping analysis.")
                return None
            
            # SDK ì„¤ì •
            genai.configure(api_key=settings.GOOGLE_API_KEY)
            model = genai.GenerativeModel('gemini-2.0-flash-exp')
            
            # ì›ë³¸ ë°ì´í„°ì—ì„œ ë¶„ì„ì— í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
            properties = record.get("properties", {})
            title = record.get("name", "No Title")
            description = properties.get("brief_summary", "")
            overall_status = properties.get("overall_status", "")
            why_stopped = properties.get("why_stopped", "")
            phase = properties.get("phase", "")
            
            # LLM í”„ë¡¬í”„íŠ¸
            system_prompt = """You are a Clinical Trial Analyst specializing in ADC (Antibody-Drug Conjugate) research.
Analyze the clinical trial data and extract structured information.

Output ONLY valid JSON in this exact format:
{
    "drug_name": "extracted drug/compound name or null",
    "target": "molecular target (e.g., HER2, TROP2) or null",
    "outcome_type": "Success|Failure|Ongoing|Unknown",
    "failure_reason": "reason if failed, null otherwise",
    "relevance_score": 0.0-1.0 (relevance to ADC research),
    "confidence": 0.0-1.0
}

Rules:
- outcome_type: "Success" if completed with positive results, "Failure" if terminated/withdrawn/negative, "Ongoing" if active, "Unknown" if unclear
- failure_reason: Only fill if outcome_type is "Failure"
- Be concise and accurate

IMPORTANT: Return ONLY raw JSON. Do not use markdown formatting like ```json ... ```.
"""

            full_prompt = f"""{system_prompt}

Clinical Trial Analysis:
Title: {title}
Phase: {phase}
Status: {overall_status}
Why Stopped: {why_stopped}
Description: {description[:1000] if description else 'N/A'}"""

            logger.info(f"ğŸš€ Requesting Gemini (Direct SDK) for record {record.get('id')}...")
            
            # ë™ê¸° í˜¸ì¶œì„ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(None, lambda: model.generate_content(full_prompt))
            
            content = response.text.strip()
            
            # ë¹„ìš© ì¶”ì  (Gemini 2.0 Flash ëŒ€ëµì  í† í° ê³„ì‚° - SDKì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸° ì–´ë ¤ìš¸ ê²½ìš° ëŒ€ë¹„)
            # ì‹¤ì œë¡œëŠ” response.usage_metadataì— ìˆìŒ
            usage = response.usage_metadata
            await cost_tracker.track_usage(
                "gemini-2.0-flash",
                usage.prompt_token_count,
                usage.candidates_token_count
            )
            
            # JSON íŒŒì‹± (json-repair ë„ì…ìœ¼ë¡œ ë°±í‹± ê³µê²© ë° ê¹¨ì§„ í˜•ì‹ ë°©ì–´)
            try:
                repaired_content = repair_json(content)
                analysis = json.loads(repaired_content)
            except Exception as parse_e:
                logger.warning(f"Standard parsing failed, trying manual strip: {parse_e}")
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0]
                elif "```" in content:
                    content = content.split("```")[1].split("```")[0]
                analysis = json.loads(content.strip())
            
            # 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸: 1. ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ & ì¶”ì¶œ
            return {
                "drug_name": analysis.get("drug_name"),
                "target": analysis.get("target"),
                "outcome_type": analysis.get("outcome_type", "Unknown"),
                "failure_reason": analysis.get("failure_reason"),
                "ai_confidence": analysis.get("confidence", 0.5),
                "relevance_score": analysis.get("relevance_score", 0.0) # í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€ í•„ìš”
            }
        
        except Exception as e:
            logger.error(f"LLM Analysis Error for record {record.get('id')}: {e}")
            return {"error": str(e)}

    async def enrich_with_pubchem(self, drug_name: Optional[str]) -> Dict[str, Any]:
        """2ë‹¨ê³„: PubChem í™”í•™ êµ¬ì¡° ìë™ ë§¤í•‘"""
        if not drug_name:
            return {}
        
        try:
            # pubchempyëŠ” ë™ê¸° ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë¯€ë¡œ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
            import pubchempy as pcp
            loop = asyncio.get_event_loop()
            
            def fetch_pubchem():
                compounds = pcp.get_compounds(drug_name, 'name')
                if compounds:
                    c = compounds[0]
                    return {
                        "smiles_code": c.isomeric_smiles,
                        "canonical_smiles": c.canonical_smiles,
                        "molecular_weight": float(c.molecular_weight) if c.molecular_weight else None
                    }
                return None

            result = await loop.run_in_executor(None, fetch_pubchem)
            return result
            
        except Exception as e:
            logger.error(f"PubChem lookup error for {drug_name}: {e}")
            return {"error": "PubChem Error"}

    async def process_pending_records(self, job_id: Optional[str] = None, max_records: int = 50):
        """
        ë¯¸ì •ì œ ë ˆì½”ë“œ ë°°ì¹˜ ì²˜ë¦¬
        - ai_refined = false ì¸ ë ˆì½”ë“œ ì¡°íšŒ
        - LLM ë¶„ì„
        - SMILES ë³´ê°•
        - DB ì—…ë°ì´íŠ¸ (ai_refined = true)
        """
        from app.api.scheduler import update_job_status, is_cancelled
        
        # ì‹œìŠ¤í…œ ì¼ì‹œì •ì§€ ì²´í¬
        if await self._is_system_paused():
            logger.info("â¸ï¸ System is PAUSED. Skipping AI Refiner.")
            if job_id:
                await update_job_status(job_id, status="skipped", errors=["System is paused"])
            return
        
        if job_id:
            await update_job_status(job_id, status="running")
        
        logger.info("ğŸ§¹ [AI Refiner] Checking for pending records...")
        
        try:
            # ë¯¸ì •ì œ ë ˆì½”ë“œ ì¡°íšŒ
            response = supabase.table("golden_set_library")\
                .select("*")\
                .eq("ai_refined", False)\
                .limit(max_records)\
                .execute()
            
            pending_items = response.data
            
            if not pending_items:
                logger.info("âœ¨ No pending items. Golden Set is clean.")
                if job_id:
                    await update_job_status(
                        job_id, 
                        status="completed", 
                        records_found=0,
                        completed_at=datetime.utcnow().isoformat()
                    )
                return
            
            if job_id:
                await update_job_status(job_id, records_found=len(pending_items))
            
            logger.info(f"ğŸ” [AI Refiner] Processing {len(pending_items)} items...")
            
            refined_count = 0
            error_count = 0
            
            for item in pending_items:
                # ì¤‘ë‹¨ ìš”ì²­ ì²´í¬
                if job_id and await is_cancelled(job_id):
                    logger.info("Refiner cancelled by user")
                    await update_job_status(job_id, status="stopped")
                    return
                
                try:
                    # ============ Smart Skip Logic ============
                    existing_drug_name = item.get("name")
                    existing_outcome = item.get("outcome_type")
                    existing_smiles = item.get("smiles_code")
                    
                    # 1ï¸âƒ£ LLM ë¶„ì„ (drug_name ë˜ëŠ” outcome_typeì´ ì—†ì„ ë•Œë§Œ)
                    if not existing_drug_name or existing_drug_name == "Unknown" or not existing_outcome:
                        logger.info(f"ğŸ¤– LLM analyzing: {item.get('id', 'unknown')[:20]}...")
                        analysis = await self.refine_single_record(item)
                    else:
                        logger.info(f"â© LLM Skip: {existing_drug_name[:30]} (already extracted)")
                        analysis = {
                            "drug_name": existing_drug_name,
                            "outcome_type": existing_outcome,
                            "failure_reason": item.get("failure_reason"),
                            "target": item.get("properties", {}).get("target")
                        }
                    
                    if analysis and "error" not in analysis:
                        drug_name = analysis.get("drug_name") or existing_drug_name
                        relevance_score = analysis.get("relevance_score", 0.0)
                        
                        # 2ï¸âƒ£ í™”í•™ êµ¬ì¡° ë§¤í•‘ (ê´€ë ¨ì„± ë†’ì„ ë•Œë§Œ)
                        pubchem_data = None
                        processing_error = None
                        
                        if relevance_score > 0.5 and drug_name:
                            if existing_smiles:
                                logger.info(f"â© PubChem Skip: {drug_name[:30]} (SMILES exists)")
                                pubchem_data = {"smiles_code": existing_smiles}
                            else:
                                logger.info(f"ğŸ”¬ PubChem lookup: {drug_name}")
                                pubchem_data = await self.enrich_with_pubchem(drug_name)
                                
                                if not pubchem_data:
                                    # [ì‹¤íŒ¨ ëŒ€ì‘] PubChem ì¡°íšŒ ì‹¤íŒ¨ ì‹œ í”ì  ë‚¨ê¸°ê¸°
                                    processing_error = "PubChem Not Found"
                                    logger.warning(f"âš ï¸ PubChem Not Found for: {drug_name}")
                        
                        # ê¸°ì¡´ propertiesì— AI ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                        updated_properties = item.get("properties", {})
                        updated_properties["ai_analysis"] = analysis
                        if "raw_data" in updated_properties:
                            del updated_properties["raw_data"]
                        
                        # 3ï¸âƒ£ DB ìƒíƒœ ì—…ë°ì´íŠ¸
                        update_payload = {
                            "name": drug_name or item.get("name"),
                            "outcome_type": analysis.get("outcome_type", "Unknown"),
                            "failure_reason": analysis.get("failure_reason"),
                            "relevance_score": relevance_score,
                            "ai_refined": True,
                            "rag_status": "processed", # ì„±ê³µ ì²˜ë¦¬
                            "processing_error": processing_error, # PubChem ì‹¤íŒ¨ ì‹œ ê¸°ë¡
                            "properties": updated_properties
                        }
                        
                        # PubChem ë°ì´í„° ë³‘í•©
                        if pubchem_data and "error" not in pubchem_data:
                            update_payload.update(pubchem_data)
                        
                        supabase.table("golden_set_library")\
                            .update(update_payload)\
                            .eq("id", item["id"])\
                            .execute()
                        
                        refined_count += 1
                        logger.info(f"âœ… Refined: {drug_name[:50] if drug_name else 'Unknown'} (Score: {relevance_score})")
                    else:
                        # ë¶„ì„ ì‹¤íŒ¨ ì‹œ ìƒì„¸ ì—ëŸ¬ ê¸°ë¡
                        error_msg = analysis.get("error") if analysis else "Unknown LLM Error"
                        supabase.table("golden_set_library")\
                            .update({
                                "processing_error": error_msg,
                                "ai_refined": True,
                                "rag_status": "failed"
                            })\
                            .eq("id", item["id"])\
                            .execute()
                        error_count += 1
                    
                    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                    if job_id:
                        await update_job_status(job_id, records_drafted=refined_count)
                    
                    # Rate limiting
                    await asyncio.sleep(0.5)
                
                except Exception as e:
                    logger.error(f"Record processing error for {item.get('id')}: {e}")
                    # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ì²˜ë¦¬ëœ ê²ƒìœ¼ë¡œ í‘œì‹œí•˜ì—¬ ë¬´í•œ ë£¨í”„ ë°©ì§€
                    try:
                        supabase.table("golden_set_library")\
                            .update({
                                "processing_error": f"Processing failed: {str(e)}",
                                "ai_refined": True, # ì¬ì‹œë„ ë°©ì§€
                                "outcome_type": "Failure",
                                "failure_reason": "System Error"
                            })\
                            .eq("id", item["id"])\
                            .execute()
                    except Exception as db_e:
                        logger.error(f"Failed to update error status: {db_e}")
                    
                    error_count += 1
            
            logger.info(f"ğŸ‰ Refiner Complete! Refined: {refined_count}, Errors: {error_count}")
            
            if job_id:
                await update_job_status(
                    job_id,
                    status="completed",
                    records_drafted=refined_count,
                    completed_at=datetime.utcnow().isoformat(),
                    errors=[f"Errors: {error_count}"] if error_count > 0 else []
                )
        
        except Exception as e:
            logger.error(f"AI Refiner Error: {e}")
            if job_id:
                await update_job_status(job_id, status="failed", errors=[str(e)])

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
ai_refiner = AIRefiner()
