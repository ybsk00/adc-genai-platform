import asyncio
import logging
from unittest.mock import MagicMock, AsyncMock

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("BatchTest")

# ì‹¤ì œ í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤ ì„í¬íŠ¸ (ê²½ë¡œ ì„¤ì •)
import sys
import os
sys.path.append(os.getcwd())

from app.services.ambeed_crawler import AmbeedCrawler

async def test_batch_logic():
    crawler = AmbeedCrawler()
    
    # ì‹¤ì œ DBì™€ í†µì‹ í•˜ì§€ ì•Šë„ë¡ Mock ì„¤ì •
    crawler._save_batch = AsyncMock()
    crawler._process_single_product = AsyncMock(return_value={"test": "data"})
    crawler._enrich_and_prepare_item = AsyncMock(return_value={
        "ambeed_cat_no": "TEST-001", 
        "product_name": "Test Product",
        "smiles_code": "C1=CC=CC=C1"
    })
    
    # update_job_status ëª¨í‚¹
    import app.api.scheduler
    app.api.scheduler.update_job_status = AsyncMock()
    app.api.scheduler.get_job_from_db = AsyncMock(return_value=None)
    app.api.scheduler.is_cancelled = AsyncMock(return_value=False)

    # crawl_category ë‚´ë¶€ì˜ í•µì‹¬ ë£¨í”„ ì‹œë®¬ë ˆì´ì…˜
    # 6ê°œì˜ ë°ì´í„°ë¥¼ ì°¾ì•˜ì„ ë•Œ, 5ê°œì—ì„œ í•œ ë²ˆ ì €ì¥ë˜ê³  ë§ˆì§€ë§‰ì— 1ê°œê°€ ì €ì¥ë˜ì–´ì•¼ í•¨
    batch_data = []
    count = 0
    limit = 6
    job_id = "test_job"
    
    logger.info("ğŸš€ Starting Batch Save Logic Test (Target: 5 items per batch)")
    
    for i in range(1, limit + 1):
        count += 1
        res = await crawler._process_single_product(None, "url", "cat")
        final_item = await crawler._enrich_and_prepare_item(res)
        
        if final_item:
            batch_data.append(final_item)
            logger.info(f"â• Item {i} added to batch. Current batch size: {len(batch_data)}")
            
            # ì‹¤ì œ ì½”ë“œì— ë°˜ì˜ëœ 5ê°œ ë‹¨ìœ„ ì €ì¥ ë¡œì§
            if len(batch_data) >= 5:
                await crawler._save_batch(batch_data)
                logger.info(f"ğŸ’¾ [SUCCESS] Batch size reached 5. _save_batch CALLED!")
                batch_data = [] # ë©”ëª¨ë¦¬ ë¹„ìš°ê¸°
    
    # ë£¨í”„ ì¢…ë£Œ í›„ ë‚¨ì€ ë°ì´í„° ì²˜ë¦¬
    if batch_data:
        await crawler._save_batch(batch_data)
        logger.info(f"ğŸ’¾ [SUCCESS] Final remaining data saved. Count: {len(batch_data)}")

    # ê²€ì¦: _save_batchê°€ ì´ 2ë²ˆ í˜¸ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸ (5ê°œ ë¬¶ìŒ + 1ê°œ ë‚¨ì€ ê²ƒ)
    save_call_count = crawler._save_batch.call_count
    logger.info(f"ğŸ“Š Total _save_batch calls: {save_call_count}")
    
    if save_call_count == 2:
        print("\nâœ… TEST PASSED: 5ê°œ ë‹¨ìœ„ë¡œ ì €ì¥ì´ ì •í™•íˆ ì‹¤í–‰ë©ë‹ˆë‹¤!")
    else:
        print("\nâŒ TEST FAILED: ì €ì¥ ë¡œì§ í™•ì¸ í•„ìš”.")

if __name__ == "__main__":
    asyncio.run(test_batch_logic())
