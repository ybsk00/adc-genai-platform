# ğŸ•µï¸â€â™‚ï¸ Project Treasure Trove: Ambeed Stealth Crawler Spec

**Objective**: Ambeed.comì˜ ADC ê´€ë ¨ ì œí’ˆ(Payload, Linker, Conjugate) ì „ëŸ‰ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.
**Critical Requirement**: ì›¹ì‚¬ì´íŠ¸ì˜ ë³´ì•ˆ ì°¨ë‹¨(IP Block/403 Error)ì„ ìš°íšŒí•˜ê¸° ìœ„í•´ User-Agent ë¡œí…Œì´ì…˜, ëœë¤ ë”œë ˆì´, ì„¸ì…˜ ìœ ì§€ ë“±ì˜ ìŠ¤í…”ìŠ¤ ê¸°ìˆ ì„ ë°˜ë“œì‹œ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

**Target Hub**: Ambeed ADC Related Products

## 1. ğŸ›¡ï¸ Anti-Blocking Strategy (ìš°íšŒ ê¸°ìˆ  ì§€ì¹¨)
**ê°œë°œì í•„ë…**: ë‹¨ìˆœ `requests.get()` ë£¨í”„ë¥¼ ëŒë¦¬ë©´ 100% ì°¨ë‹¨ë‹¹í•©ë‹ˆë‹¤. ì•„ë˜ ê¸°ìˆ ì„ ëª¨ë‘ ì ìš©í•˜ì‹­ì‹œì˜¤.

### Random User-Agent Rotation
ë§¤ ìš”ì²­ë§ˆë‹¤ ë¸Œë¼ìš°ì € ì •ë³´(User-Agent)ë¥¼ ìµœì‹  Chrome, Firefox, Safari ë“±ìœ¼ë¡œ ëœë¤í•˜ê²Œ ë³€ê²½í•˜ì—¬ "ì—¬ëŸ¬ ì‚¬ëŒì´ ì ‘ì†í•˜ëŠ” ì²™" í•´ì•¼ í•©ë‹ˆë‹¤.
*   **ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ì²œ**: `fake-useragent`

### Human-like Delays (Random Sleep)
í˜ì´ì§€ ì´ë™ ì‹œ ê¸°ê³„ì ìœ¼ë¡œ 1ì´ˆë§ˆë‹¤ ìš”ì²­í•˜ì§€ ë§ê³ , **2ì´ˆ~5ì´ˆ ì‚¬ì´ì˜ ëœë¤í•œ ì‹œê°„**ì„ ì‰¬ì–´ì•¼ í•©ë‹ˆë‹¤.

### Referer Header Manipulation
ìƒì„¸ í˜ì´ì§€ë¡œ ë“¤ì–´ê°ˆ ë•Œ, ë°˜ë“œì‹œ **"ì´ì „ ëª©ë¡ í˜ì´ì§€ì—ì„œ í´ë¦­í•´ì„œ ë“¤ì–´ì™”ìŒ"**ì„ ì¦ëª…í•˜ëŠ” `Referer` í—¤ë”ë¥¼ ì‹¬ì–´ì•¼ í•©ë‹ˆë‹¤.

### Error Handling & Backoff
403(Forbidden)ì´ë‚˜ 429(Too Many Requests) ì—ëŸ¬ ë°œìƒ ì‹œ, ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë©ˆì¶”ì§€ ë§ê³  **30ì´ˆ ì´ìƒ ëŒ€ê¸° í›„ ì¬ì‹œë„(Exponential Backoff)** í•˜ì‹­ì‹œì˜¤.

## 2. ğŸ’¾ Database Schema (PostgreSQL)
```sql
CREATE TABLE IF NOT EXISTS commercial_reagents (
    id uuid DEFAULT gen_random_uuid() PRIMARY KEY,
    ambeed_cat_no text UNIQUE NOT NULL,
    product_name text,
    category text, -- 'Payload', 'Linker', 'Conjugate'
    cas_number text,
    smiles_code text, -- ìƒì„¸ í˜ì´ì§€ 'Product Details'ì—ì„œ íŒŒì‹±
    molecular_weight text,
    formula text,
    price_data jsonb,
    stock_status text,
    product_url text,
    crawled_at timestamptz DEFAULT now(),
    embedding vector(1536) 
);
```

## 3. ğŸ Stealth Crawler Python Logic (services/crawler_stealth.py)
ì•„ë˜ ì½”ë“œëŠ” ì°¨ë‹¨ì„ íšŒí”¼í•˜ê¸° ìœ„í•œ í•µì‹¬ ë¡œì§ì´ í¬í•¨ëœ í…œí”Œë¦¿ì…ë‹ˆë‹¤.

```python
import requests
from bs4 import BeautifulSoup
import time
import random
from fake_useragent import UserAgent # pip install fake-useragent

class AmbeedStealthScraper:
    BASE_URL = "https://www.ambeed.com"
    
    def __init__(self):
        self.ua = UserAgent()
        self.session = requests.Session() # ì„¸ì…˜ ìœ ì§€ (ì¿ í‚¤ ê´€ë¦¬)
        
    def get_headers(self, referer=None):
        headers = {
            'User-Agent': self.ua.random, # ë§¤ë²ˆ ë‹¤ë¥¸ ë¸Œë¼ìš°ì €ì¸ ì²™
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        }
        if referer:
            headers['Referer'] = referer
        return headers

    def safe_request(self, url, referer=None):
        """ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•œ ì•ˆì „í•œ ìš”ì²­ í•¨ìˆ˜"""
        retries = 3
        for i in range(retries):
            try:
                # 1. ì‚¬ëŒì²˜ëŸ¼ ëœë¤í•˜ê²Œ ì‰¬ê¸° (2~5ì´ˆ)
                sleep_time = random.uniform(2, 5)
                time.sleep(sleep_time)
                
                print(f"ğŸ•µï¸ Scraping: {url} (Delay: {sleep_time:.2f}s)")
                
                response = self.session.get(
                    url, 
                    headers=self.get_headers(referer), 
                    timeout=15
                )
                
                # 2. ì°¨ë‹¨ ê°ì§€ ì‹œ ëŒ€ê¸°
                if response.status_code in [403, 429, 503]:
                    print(f"âš ï¸ Blocked ({response.status_code}). Cooling down for 60s...")
                    time.sleep(60) # 1ë¶„ íœ´ì‹
                    self.session = requests.Session() # ì„¸ì…˜ ì´ˆê¸°í™” (ìƒˆ ì‹ ë¶„ ì„¸íƒ)
                    continue
                
                response.raise_for_status()
                return response
            
            except Exception as e:
                print(f"âŒ Error: {e}")
                time.sleep(5)
        return None

    def parse_detail_page(self, url, category, referer_url):
        res = self.safe_request(url, referer=referer_url)
        if not res: return
        
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # [í•µì‹¬] ìƒì„¸ ìŠ¤í™ í…Œì´ë¸” íŒŒì‹± (ìŠ¤í¬ë¦°ìƒ· ê¸°ë°˜)
        details = {}
        # ì‹¤ì œ ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ì¶° Selector ìˆ˜ì • í•„ìš”
        # ì˜ˆ: <td class="label">SMILES Code :</td><td class="value">...</td>
        for row in soup.select('tr'): 
            text = row.get_text(strip=True)
            if "SMILES Code" in text:
                details['smiles'] = text.split(':')[-1].strip()
            elif "CAS No." in text:
                details['cas'] = text.split(':')[-1].strip()
        
        # DB ì €ì¥ ë¡œì§ í˜¸ì¶œ
        self.save_to_db(details)

    def run(self):
        # ... (ì¹´í…Œê³ ë¦¬ ìˆœíšŒ ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼, safe_request ì‚¬ìš© í•„ìˆ˜) ...
        pass
```

## 4. ğŸ§  RAG Integration (í™œìš© ì‹œë‚˜ë¦¬ì˜¤)
í¬ë¡¤ë§ ëœ ë°ì´í„°ëŠ” ë‹¨ìˆœ ì €ì¥ì´ ì•„ë‹ˆë¼ ë²¡í„° ì„ë² ë”© ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

*   **Trigger**: í¬ë¡¤ë§ì´ ì™„ë£Œëœ ì§í›„ (`save_to_db` ì´í›„).
*   **Action**: SMILES Codeì™€ Product Descriptionì„ í…ìŠ¤íŠ¸ë¡œ í•©ì³ì„œ OpenAI Embedding API í˜¸ì¶œ.
*   **Query**: ì‚¬ìš©ìê°€ "MMAEë‘ êµ¬ì¡°ê°€ ë¹„ìŠ·í•œë° ë” ì‹¼ ê±° ìˆì–´?"ë¼ê³  ë¬¼ìœ¼ë©´,
*   **Search**: ë²¡í„° ìœ ì‚¬ë„(Cosine Similarity) + ê°€ê²© ì •ë ¬(ASC)ë¡œ Ambeed ë°ì´í„°ë¥¼ ì¶”ì²œ.
